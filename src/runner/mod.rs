pub mod worker;
pub mod data_pool;
pub mod proxy_pool;
pub mod output;
pub mod job;
pub mod job_manager;

use serde::{Deserialize, Serialize};
use std::collections::VecDeque;
use std::sync::atomic::{AtomicBool, AtomicU64, AtomicUsize, Ordering};
use std::sync::Arc;
use tokio::sync::{mpsc, oneshot, Mutex};

use crate::pipeline::{Pipeline, ProxyMode};
use crate::sidecar::protocol::{SidecarRequest, SidecarResponse};
use data_pool::DataPool;
use proxy_pool::ProxyPool;

/// Single check result pushed to the live feed ring buffer.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ResultEntry {
    /// The data line that was checked (e.g. "user:pass")
    pub data_line: String,
    /// Outcome: "SUCCESS" | "FAIL" | "BAN" | "RETRY" | "ERROR" | "NONE"
    pub status: String,
    /// Proxy used for this check, if any
    pub proxy: Option<String>,
    /// Captures from a successful check (non-empty only for SUCCESS)
    #[serde(default)]
    pub captures: std::collections::HashMap<String, String>,
    /// Error message when status == "ERROR"
    #[serde(default)]
    pub error: Option<String>,
    /// Wall-clock millis since epoch
    pub ts_ms: u64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RunnerStats {
    pub total: usize,
    pub processed: usize,
    pub consumed: usize,
    pub hits: usize,
    pub fails: usize,
    pub bans: usize,
    pub retries: usize,
    pub errors: usize,
    pub cpm: f64,
    pub active_threads: usize,
    pub elapsed_secs: f64,
    #[serde(default)]
    pub recent_results: Vec<ResultEntry>,
}

/// Capacity of the live result ring buffer.  100 entries â‰ˆ last few seconds
/// of work at typical CPM rates; keeping it small avoids lock contention.
const RESULT_FEED_CAP: usize = 100;

pub struct RunnerOrchestrator {
    pipeline: Pipeline,
    proxy_mode: ProxyMode,
    data_pool: Arc<DataPool>,
    proxy_pool: Arc<ProxyPool>,
    sidecar_tx: mpsc::Sender<(SidecarRequest, oneshot::Sender<SidecarResponse>)>,
    thread_count: usize,
    running: Arc<AtomicBool>,
    paused: Arc<AtomicBool>,
    stats: Arc<RunnerStatsInner>,
    hits_tx: mpsc::Sender<HitResult>,
    output_writer: Option<Arc<output::OutputWriter>>,
    plugin_manager: Option<Arc<crate::plugin::manager::PluginManager>>,
    result_feed: Arc<Mutex<VecDeque<ResultEntry>>>,
}

pub(crate) struct RunnerStatsInner {
    processed: AtomicUsize,
    consumed: AtomicUsize,
    hits: AtomicUsize,
    fails: AtomicUsize,
    bans: AtomicUsize,
    retries: AtomicUsize,
    errors: AtomicUsize,
    active_threads: AtomicUsize,
    start_time_ms: AtomicU64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct HitResult {
    pub data_line: String,
    pub captures: std::collections::HashMap<String, String>,
    pub proxy: Option<String>,
}

impl RunnerOrchestrator {
    pub fn new(
        pipeline: Pipeline,
        proxy_mode: ProxyMode,
        data_pool: DataPool,
        proxy_pool: ProxyPool,
        sidecar_tx: mpsc::Sender<(SidecarRequest, oneshot::Sender<SidecarResponse>)>,
        thread_count: usize,
        hits_tx: mpsc::Sender<HitResult>,
        plugin_manager: Option<Arc<crate::plugin::manager::PluginManager>>,
    ) -> Self {
        let ow = if pipeline.output_settings.save_to_file {
            Some(Arc::new(output::OutputWriter::new(
                &pipeline.output_settings,
                &pipeline.name,
            )))
        } else {
            None
        };
        Self {
            pipeline,
            proxy_mode,
            data_pool: Arc::new(data_pool),
            proxy_pool: Arc::new(proxy_pool),
            sidecar_tx,
            thread_count,
            running: Arc::new(AtomicBool::new(false)),
            paused: Arc::new(AtomicBool::new(false)),
            stats: Arc::new(RunnerStatsInner {
                processed: AtomicUsize::new(0),
                consumed: AtomicUsize::new(0),
                hits: AtomicUsize::new(0),
                fails: AtomicUsize::new(0),
                bans: AtomicUsize::new(0),
                retries: AtomicUsize::new(0),
                errors: AtomicUsize::new(0),
                active_threads: AtomicUsize::new(0),
                start_time_ms: AtomicU64::new(0),
            }),
            hits_tx,
            output_writer: ow,
            plugin_manager,
            result_feed: Arc::new(Mutex::new(VecDeque::with_capacity(RESULT_FEED_CAP))),
        }
    }

    pub async fn start(&self) {
        self.running.store(true, Ordering::SeqCst);
        self.paused.store(false, Ordering::SeqCst);

        let now = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap_or_default()
            .as_millis() as u64;
        self.stats.start_time_ms.store(now, Ordering::SeqCst);

        let gradual = self.pipeline.runner_settings.start_threads_gradually;
        let delay_ms = self.pipeline.runner_settings.gradual_delay_ms as u64;
        let max_retries = self.pipeline.runner_settings.max_retries;
        let proxy_mode = self.proxy_mode.clone();

        // Cap total ramp-up time to 3 s so high thread counts don't stall.
        // e.g. 1000 threads with delay_ms=100 would otherwise take 100 s to start.
        let effective_delay_ms = if gradual && self.thread_count > 1 {
            let cap = (3000u64 / self.thread_count as u64).max(1);
            delay_ms.min(cap)
        } else {
            delay_ms
        };

        eprintln!("[runner] starting {} threads (gradual={}, delay={}ms)",
            self.thread_count, gradual, if gradual { effective_delay_ms } else { 0 });

        let mut handles = Vec::new();

        for i in 0..self.thread_count {
            if gradual && i > 0 {
                tokio::time::sleep(std::time::Duration::from_millis(effective_delay_ms)).await;
            }

            let pipeline = self.pipeline.clone();
            let proxy_mode_w = proxy_mode.clone();
            let data_pool = self.data_pool.clone();
            let proxy_pool = self.proxy_pool.clone();
            let sidecar_tx = self.sidecar_tx.clone();
            let running = self.running.clone();
            let paused = self.paused.clone();
            let stats = self.stats.clone();
            let hits_tx = self.hits_tx.clone();
            let output_writer = self.output_writer.clone();
            let plugin_manager = self.plugin_manager.clone();
            let result_feed = self.result_feed.clone();

            let handle = tokio::spawn(async move {
                worker::run_worker(
                    pipeline,
                    proxy_mode_w,
                    max_retries,
                    data_pool,
                    proxy_pool,
                    sidecar_tx,
                    running,
                    paused,
                    stats,
                    hits_tx,
                    output_writer,
                    plugin_manager,
                    result_feed,
                ).await;
            });
            handles.push(handle);
        }

        for handle in handles {
            let _ = handle.await;
        }

        self.running.store(false, Ordering::SeqCst);
    }

    pub fn pause(&self) {
        self.paused.store(true, Ordering::SeqCst);
    }

    pub fn resume(&self) {
        self.paused.store(false, Ordering::SeqCst);
    }

    pub fn stop(&self) {
        self.running.store(false, Ordering::SeqCst);
    }

    pub fn get_stats(&self) -> RunnerStats {
        let now = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap_or_default()
            .as_millis() as u64;
        let start = self.stats.start_time_ms.load(Ordering::Relaxed);
        let elapsed_secs = if start > 0 { (now - start) as f64 / 1000.0 } else { 0.0 };
        let processed = self.stats.processed.load(Ordering::Relaxed);
        let cpm = if elapsed_secs > 0.0 { processed as f64 / elapsed_secs * 60.0 } else { 0.0 };

        // Snapshot the live feed (non-blocking try_lock; return empty if contended)
        let recent_results = self.result_feed.try_lock()
            .map(|feed| feed.iter().cloned().collect::<Vec<_>>())
            .unwrap_or_default();

        RunnerStats {
            total: self.data_pool.total(),
            processed,
            consumed: self.data_pool.consumed(),
            hits: self.stats.hits.load(Ordering::Relaxed),
            fails: self.stats.fails.load(Ordering::Relaxed),
            bans: self.stats.bans.load(Ordering::Relaxed),
            retries: self.stats.retries.load(Ordering::Relaxed),
            errors: self.stats.errors.load(Ordering::Relaxed),
            cpm,
            active_threads: self.stats.active_threads.load(Ordering::Relaxed),
            elapsed_secs,
            recent_results,
        }
    }

    pub fn is_running(&self) -> bool {
        self.running.load(Ordering::Relaxed)
    }
}
